{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea8d6228",
   "metadata": {},
   "source": [
    "This file is my implementation of ehsan's code for testing model A on the images generated by the same model (FGSM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3836b056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.10.19 (main, Oct 21 2025, 16:43:05) [GCC 11.2.0]\n",
      "[eval_pretrained_models] using device: cuda\n",
      "Found 1000 classes. train_samples=2929 test_samples=568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nsakr2/.conda/envs/condavenv/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/nsakr2/.conda/envs/condavenv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "\n",
      "[alexnet] clean accuracy on validation set: 0.5792\n",
      "[alexnet] FGSM eps=0.1 adversarial accuracy: 0.0053; acc percent: 0.53%\n",
      "[alexnet] FGSM eps=0.01 adversarial accuracy: 0.1690; acc percent: 16.90%\n",
      "[alexnet] FGSM eps=0.001 adversarial accuracy: 0.5106; acc percent: 51.06%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nsakr2/.conda/envs/condavenv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[vgg16] clean accuracy on validation set: 0.7077\n",
      "[vgg16] FGSM eps=0.1 adversarial accuracy: 0.0511; acc percent: 5.11%\n",
      "[vgg16] FGSM eps=0.01 adversarial accuracy: 0.1373; acc percent: 13.73%\n",
      "[vgg16] FGSM eps=0.001 adversarial accuracy: 0.5845; acc percent: 58.45%\n",
      "\n",
      "[cornet] clean accuracy on validation set: 0.7025\n",
      "[cornet] FGSM eps=0.1 adversarial accuracy: 0.0387; acc percent: 3.87%\n",
      "[cornet] FGSM eps=0.01 adversarial accuracy: 0.1673; acc percent: 16.73%\n",
      "[cornet] FGSM eps=0.001 adversarial accuracy: 0.6127; acc percent: 61.27%\n",
      "{'alexnet': {'clean_acc': 0.579225352112676, 'adv_accs': {0.1: 0.00528169014084507, 0.01: 0.16901408450704225, 0.001: 0.5105633802816901}}, 'vgg16': {'clean_acc': 0.7077464788732394, 'adv_accs': {0.1: 0.051056338028169015, 0.01: 0.13732394366197184, 0.001: 0.5845070422535211}}, 'cornet': {'clean_acc': 0.7024647887323944, 'adv_accs': {0.1: 0.03873239436619718, 0.01: 0.16725352112676056, 0.001: 0.6126760563380281}}}\n"
     ]
    }
   ],
   "source": [
    "# Running not on full dataset: train_samples=2929 test_samples=568\n",
    "# Put this in a Jupyter cell\n",
    "from __future__ import annotations\n",
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Dict\n",
    "from cornet import cornet_s\n",
    "import sys\n",
    "print(sys.version)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "\n",
    "# -------------------------\n",
    "# Dataset / splitting (same deterministic split used previously)\n",
    "# -------------------------\n",
    "class FewPerClassImageDataset(Dataset):\n",
    "    \"\"\"Simple dataset wrapping lists of (image_path, label).\"\"\"\n",
    "    def __init__(self, samples: List[Tuple[str, int]], transform=None):\n",
    "        self.samples = samples\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        p, label = self.samples[idx]\n",
    "        img = Image.open(p).convert(\"RGB\")\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n",
    "\n",
    "def build_splits_from_folder(root: str, train_per_class: int = 3, test_per_class: int = 1,\n",
    "                             shuffle_within_class: bool = False) -> Tuple[List[Tuple[str,int]], List[Tuple[str,int]], Dict[int,str]]:\n",
    "    \"\"\"\n",
    "    Walks `root` and for each subfolder (class) picks the first `train_per_class` images\n",
    "    as train and next `test_per_class` images as test. Returns lists of (path, label).\n",
    "    Also returns a label -> class_name map.\n",
    "    \"\"\"\n",
    "    root_p = Path(root)\n",
    "    assert root_p.exists(), f\"Data root not found: {root}\"\n",
    "    classes = sorted([d for d in root_p.iterdir() if d.is_dir()])\n",
    "    train_samples = []\n",
    "    test_samples = []\n",
    "    class_map = {}\n",
    "    for label, cls in enumerate(classes):\n",
    "        imgs = sorted([p for p in cls.iterdir() if p.is_file()])\n",
    "        if shuffle_within_class:\n",
    "            random.shuffle(imgs)\n",
    "        # Basic safety: slice to available images\n",
    "        tr = imgs[:train_per_class]\n",
    "        te = imgs[train_per_class:train_per_class + test_per_class]\n",
    "        for p in tr:\n",
    "            train_samples.append((str(p), label))\n",
    "        for p in te:\n",
    "            test_samples.append((str(p), label))\n",
    "        class_map[label] = cls.name\n",
    "    return train_samples, test_samples, class_map\n",
    "\n",
    "# -------------------------\n",
    "# FGSM helpers\n",
    "# -------------------------\n",
    "def fgsm_perturb_from_grad(x: torch.Tensor, grad: torch.Tensor, epsilon: float) -> torch.Tensor:\n",
    "    \"\"\"Perturb in normalized input space using gradient sign.\"\"\"\n",
    "    return torch.clamp(x + epsilon * grad.sign(), -10.0, 10.0).detach()\n",
    "\n",
    "# -------------------------\n",
    "# Evaluation functions\n",
    "# -------------------------\n",
    "def evaluate_clean(model: torch.nn.Module, loader: DataLoader, device: torch.device) -> float:\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            out = model(x)\n",
    "            preds = out.argmax(dim=1)\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += y.size(0)\n",
    "    return (correct / total) if total > 0 else 0.0\n",
    "\n",
    "def evaluate_fgsm(model: torch.nn.Module, loader: DataLoader, device: torch.device,\n",
    "                  epsilons: List[float], loss_fn=None) -> Dict[float, float]:\n",
    "    \"\"\"\n",
    "    Runs FGSM on the loader (same validation set). Returns mapping epsilon -> adversarial accuracy.\n",
    "    Uses one backward per batch and re-uses gradient sign for efficiency.\n",
    "    \"\"\"\n",
    "    if loss_fn is None:\n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "    model.eval()\n",
    "    results = {eps: {'correct': 0, 'total': 0} for eps in epsilons}\n",
    "\n",
    "    for x, y in loader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        # Need gradients w.r.t. inputs\n",
    "        x.requires_grad = True\n",
    "        out = model(x)\n",
    "        loss = loss_fn(out, y)\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        grad = x.grad.data  # gradient of loss wrt normalized input\n",
    "        for eps in epsilons:\n",
    "            x_adv = fgsm_perturb_from_grad(x, grad, eps)\n",
    "            with torch.no_grad():\n",
    "                out_adv = model(x_adv)\n",
    "                preds = out_adv.argmax(dim=1)\n",
    "                results[eps]['correct'] += (preds == y).sum().item()\n",
    "                results[eps]['total'] += y.size(0)\n",
    "        # clear grad for next batch\n",
    "        x.grad = None\n",
    "\n",
    "    accs = {eps: (results[eps]['correct'] / results[eps]['total'] if results[eps]['total'] > 0 else 0.0)\n",
    "            for eps in epsilons}\n",
    "    return accs\n",
    "\n",
    "# -------------------------\n",
    "# Model helpers (pretrained)\n",
    "# -------------------------\n",
    "def load_pretrained_alexnet(num_classes_expected:int, device:torch.device):\n",
    "    model = models.alexnet(pretrained=True)  # pretrained weights\n",
    "    # If dataset classes != 1000 then user is evaluating a different label space.\n",
    "    # We'll keep pretrained classifier only if num_classes_expected == 1000.\n",
    "    print(num_classes_expected)\n",
    "    if num_classes_expected != 1000:\n",
    "        print(f\"[warning] dataset has {num_classes_expected} classes != 1000. Replacing AlexNet final classifier (random init).\")\n",
    "        in_feats = model.classifier[-1].in_features\n",
    "        model.classifier[-1] = nn.Linear(in_feats, num_classes_expected)\n",
    "    return model.to(device)\n",
    "\n",
    "def load_pretrained_vgg16(num_classes_expected:int, device:torch.device):\n",
    "    model = models.vgg16(pretrained=True)\n",
    "    if num_classes_expected != 1000:\n",
    "        print(f\"[warning] dataset has {num_classes_expected} classes != 1000. Replacing VGG16 final classifier (random init).\")\n",
    "        in_feats = model.classifier[-1].in_features\n",
    "        model.classifier[-1] = nn.Linear(in_feats, num_classes_expected)\n",
    "    return model.to(device)\n",
    "\n",
    "def load_pretrained_cornet(num_classes_expected: int, device: torch.device):\n",
    "    # Load CORnet-S (ImageNet-pretrained)\n",
    "    model = cornet_s(pretrained=True)\n",
    "\n",
    "    # CORnet-S classifier is `decoder`\n",
    "    if num_classes_expected != 1000:\n",
    "        in_feats = model.decoder.in_features\n",
    "        model.decoder = nn.Linear(in_feats, num_classes_expected)\n",
    "        print(\n",
    "            f\"[warning] CORnet-S: dataset has {num_classes_expected} classes != 1000; \"\n",
    "            \"final layer replaced (random init).\"\n",
    "        )\n",
    "    return model.to(device)\n",
    "# -------------------------\n",
    "# Main evaluation runner (no training)\n",
    "# -------------------------\n",
    "def eval_pretrained_models(\n",
    "    data_dir: str,\n",
    "    train_per_class: int = 3,\n",
    "    test_per_class: int = 1,\n",
    "    batch_size: int = 128,\n",
    "    num_workers: int = 4,\n",
    "    device: str | None = None,\n",
    "    models_to_run: List[str] = (\"alexnet\", \"vgg16\", \"cornet\"),\n",
    "    epsilons: List[float] = (0.1, 0.01, 0.001),\n",
    "):\n",
    "    \"\"\"\n",
    "    Load pretrained AlexNet & VGG16 and evaluate on the validation/test split (no training).\n",
    "    Also run FGSM on the SAME validation set.\n",
    "\n",
    "    Example:\n",
    "      eval_pretrained_models(\"/path/to/root\", batch_size=64, device=\"cuda:0\")\n",
    "    \"\"\"\n",
    "    device = torch.device(device if device else (\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "    print(f\"[eval_pretrained_models] using device: {device}\")\n",
    "\n",
    "    train_samples, test_samples, class_map = build_splits_from_folder(data_dir, train_per_class=train_per_class, test_per_class=test_per_class)\n",
    "    n_classes = len(class_map)\n",
    "    print(f\"Found {n_classes} classes. train_samples={len(train_samples)} test_samples={len(test_samples)}\")\n",
    "\n",
    "    # Deterministic transforms: 224x224, same for train & test (we only evaluate on test here)\n",
    "    input_size = 224\n",
    "    test_transform = T.Compose([\n",
    "        T.Resize(256),\n",
    "        T.CenterCrop(224),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
    "    ])\n",
    "\n",
    "    test_ds = FewPerClassImageDataset(test_samples, transform=test_transform)\n",
    "    test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "    results = {}\n",
    "    for model_name in models_to_run:\n",
    "        model_name = model_name.lower()\n",
    "        if model_name == \"alexnet\":\n",
    "            model = load_pretrained_alexnet(n_classes, device)\n",
    "        elif model_name == \"vgg16\":\n",
    "            model = load_pretrained_vgg16(n_classes, device)\n",
    "        elif model_name == \"cornet\" or \"cornet_s\":\n",
    "            model = load_pretrained_cornet(n_classes, device)\n",
    "        else:\n",
    "            print(f\"[eval_pretrained_models] unknown model '{model_name}' - skipping\")\n",
    "            continue\n",
    "\n",
    "        # Evaluate clean accuracy on validation set\n",
    "        clean_acc = evaluate_clean(model, test_loader, device)\n",
    "        print(f\"\\n[{model_name}] clean accuracy on validation set: {clean_acc:.4f}\")\n",
    "\n",
    "        # Evaluate FGSM adversarial accuracies on same validation set\n",
    "        adv_accs = evaluate_fgsm(model, test_loader, device, list(epsilons), loss_fn=nn.CrossEntropyLoss())\n",
    "        for eps, acc in adv_accs.items():\n",
    "            print(f\"[{model_name}] FGSM eps={eps:.4g} adversarial accuracy: {acc:.4f}; acc percent: {acc*100:.2f}%\")\n",
    "\n",
    "        results[model_name] = {\"clean_acc\": clean_acc, \"adv_accs\": adv_accs}\n",
    "\n",
    "    return results\n",
    "\n",
    "# -------------------------\n",
    "# Example invocation (edit path and run in cell)\n",
    "# -------------------------\n",
    "# res = eval_pretrained_models(\"/path/to/root\", batch_size=64, device=None)\n",
    "# print(res)\n",
    "\n",
    "res = eval_pretrained_models(\n",
    "    \"val/val\",\n",
    "    batch_size=16,\n",
    "    device=None,\n",
    "    models_to_run=(\"alexnet\", \"vgg16\", \"cornet\"))\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2854a4e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[eval_pretrained_on_all_test] using device: cuda:0\n",
      "Found 1000 classes and 3923 total images (all used as test samples).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nsakr2/.conda/envs/condavenv/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/nsakr2/.conda/envs/condavenv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating alexnet on full dataset ---\n",
      "alexnet clean accuracy: 0.5631\n",
      "alexnet FGSM eps=0.005 adv accuracy: 0.3026; acc percent: 30.26%\n",
      "alexnet FGSM eps=0.01 adv accuracy: 0.1637; acc percent: 16.37%\n",
      "alexnet FGSM eps=0.02 adv accuracy: 0.0612; acc percent: 6.12%\n",
      "alexnet FGSM eps=0.03 adv accuracy: 0.0303; acc percent: 3.03%\n",
      "alexnet FGSM eps=0.05 adv accuracy: 0.0112; acc percent: 1.12%\n",
      "alexnet FGSM eps=0.1 adv accuracy: 0.0054; acc percent: 0.54%\n",
      "alexnet FGSM eps=0.2 adv accuracy: 0.0046; acc percent: 0.46%\n",
      "alexnet FGSM eps=0.3 adv accuracy: 0.0028; acc percent: 0.28%\n",
      "alexnet FGSM eps=0.5 adv accuracy: 0.0020; acc percent: 0.20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nsakr2/.conda/envs/condavenv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating vgg16 on full dataset ---\n",
      "vgg16 clean accuracy: 0.7043\n",
      "vgg16 FGSM eps=0.005 adv accuracy: 0.2796; acc percent: 27.96%\n",
      "vgg16 FGSM eps=0.01 adv accuracy: 0.1318; acc percent: 13.18%\n",
      "vgg16 FGSM eps=0.02 adv accuracy: 0.0551; acc percent: 5.51%\n",
      "vgg16 FGSM eps=0.03 adv accuracy: 0.0367; acc percent: 3.67%\n",
      "vgg16 FGSM eps=0.05 adv accuracy: 0.0296; acc percent: 2.96%\n",
      "vgg16 FGSM eps=0.1 adv accuracy: 0.0298; acc percent: 2.98%\n",
      "vgg16 FGSM eps=0.2 adv accuracy: 0.0362; acc percent: 3.62%\n",
      "vgg16 FGSM eps=0.3 adv accuracy: 0.0367; acc percent: 3.67%\n",
      "vgg16 FGSM eps=0.5 adv accuracy: 0.0275; acc percent: 2.75%\n",
      "\n",
      "--- Evaluating cornet on full dataset ---\n",
      "cornet clean accuracy: 0.7214\n",
      "cornet FGSM eps=0.005 adv accuracy: 0.3569; acc percent: 35.69%\n",
      "cornet FGSM eps=0.01 adv accuracy: 0.1960; acc percent: 19.60%\n",
      "cornet FGSM eps=0.02 adv accuracy: 0.0795; acc percent: 7.95%\n",
      "cornet FGSM eps=0.03 adv accuracy: 0.0510; acc percent: 5.10%\n",
      "cornet FGSM eps=0.05 adv accuracy: 0.0339; acc percent: 3.39%\n",
      "cornet FGSM eps=0.1 adv accuracy: 0.0298; acc percent: 2.98%\n",
      "cornet FGSM eps=0.2 adv accuracy: 0.0352; acc percent: 3.52%\n",
      "cornet FGSM eps=0.3 adv accuracy: 0.0393; acc percent: 3.93%\n",
      "cornet FGSM eps=0.5 adv accuracy: 0.0436; acc percent: 4.36%\n",
      "[eval_pretrained_on_all_test] done.\n",
      "{'alexnet': {'clean_acc': 0.563089472342595, 'adv_accs': {0.005: 0.3025745602854958, 0.01: 0.16365026765230692, 0.02: 0.0611776701503951, 0.03: 0.030333928116237575, 0.05: 0.011215906194239103, 0.1: 0.005353046138159572, 0.2: 0.004588325261279633, 0.3: 0.002803976548559776, 0.5: 0.002039255671679837}}, 'vgg16': {'clean_acc': 0.7043079276064237, 'adv_accs': {0.005: 0.2796329339790976, 0.01: 0.13178689778230945, 0.02: 0.055059903135355595, 0.03: 0.036706602090237066, 0.05: 0.029569207239357635, 0.1: 0.029824114198317615, 0.2: 0.036196788172317106, 0.3: 0.036706602090237066, 0.5: 0.027529951567677798}}, 'cornet': {'clean_acc': 0.7213866938567423, 'adv_accs': {0.005: 0.35686974254397147, 0.01: 0.19602345144022432, 0.02: 0.07953097119551364, 0.03: 0.05098139179199592, 0.05: 0.033902625541677285, 0.1: 0.029824114198317615, 0.2: 0.035177160336477185, 0.3: 0.03925567167983686, 0.5: 0.04358908998215651}}}\n"
     ]
    }
   ],
   "source": [
    "# Running on full dataset: 3923 total images\n",
    "# Put this into a Jupyter notebook cell\n",
    "from __future__ import annotations\n",
    "import os\n",
    "from cornet import cornet_s\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "\n",
    "# -------------------------\n",
    "# Dataset: ALL images = test set\n",
    "# -------------------------\n",
    "class AllImagesAsTestDataset(Dataset):\n",
    "    \"\"\"Wraps a list of (image_path, label) - used as the entire test set (no split).\"\"\"\n",
    "    def __init__(self, samples: List[Tuple[str, int]], transform=None):\n",
    "        self.samples = samples\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        p, label = self.samples[idx]\n",
    "        img = Image.open(p).convert(\"RGB\")\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n",
    "\n",
    "def build_all_test_samples(root: str, sort_filenames: bool = True) -> Tuple[List[Tuple[str,int]], Dict[int, str]]:\n",
    "    \"\"\"\n",
    "    Walks `root` and builds a list of (image_path, label) for *all* files in each class folder.\n",
    "    Label assigned by sorted folder order. Returns samples and class_map.\n",
    "    \"\"\"\n",
    "    root_p = Path(root)\n",
    "    assert root_p.exists(), f\"Data root not found: {root}\"\n",
    "    class_dirs = sorted([d for d in root_p.iterdir() if d.is_dir()])\n",
    "    samples = []\n",
    "    class_map = {}\n",
    "    for label, cls in enumerate(class_dirs):\n",
    "        imgs = [p for p in cls.iterdir() if p.is_file()]\n",
    "        if sort_filenames:\n",
    "            imgs = sorted(imgs)\n",
    "        for p in imgs:\n",
    "            samples.append((str(p), label))\n",
    "        class_map[label] = cls.name\n",
    "    return samples, class_map\n",
    "\n",
    "# -------------------------\n",
    "# FGSM helper (normalized-space)\n",
    "# -------------------------\n",
    "def fgsm_perturb_from_grad(x: torch.Tensor, grad: torch.Tensor, epsilon: float) -> torch.Tensor:\n",
    "    \"\"\"Return perturbed inputs in normalized input space using gradient sign.\"\"\"\n",
    "    return torch.clamp(x + epsilon * grad.sign(), -10.0, 10.0).detach()\n",
    "\n",
    "# -------------------------\n",
    "# Evaluation (clean + FGSM)\n",
    "# -------------------------\n",
    "def evaluate_clean(model: nn.Module, loader: DataLoader, device: torch.device) -> float:\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            out = model(x)\n",
    "            preds = out.argmax(dim=1)\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += y.size(0)\n",
    "    return (correct / total) if total > 0 else 0.0\n",
    "\n",
    "def evaluate_fgsm(model: nn.Module, loader: DataLoader, device: torch.device,\n",
    "                  epsilons: List[float], loss_fn=None) -> Dict[float, float]:\n",
    "    if loss_fn is None:\n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "    model.eval()\n",
    "    results = {eps: {'correct': 0, 'total': 0} for eps in epsilons}\n",
    "\n",
    "    for x, y in loader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        x.requires_grad = True\n",
    "        out = model(x)\n",
    "        loss = loss_fn(out, y)\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        grad = x.grad.data\n",
    "        for eps in epsilons:\n",
    "            x_adv = fgsm_perturb_from_grad(x, grad, eps)\n",
    "            with torch.no_grad():\n",
    "                out_adv = model(x_adv)\n",
    "                preds = out_adv.argmax(dim=1)\n",
    "                results[eps]['correct'] += (preds == y).sum().item()\n",
    "                results[eps]['total'] += y.size(0)\n",
    "        x.grad = None\n",
    "\n",
    "    return {eps: (results[eps]['correct'] / results[eps]['total'] if results[eps]['total'] > 0 else 0.0)\n",
    "            for eps in epsilons}\n",
    "\n",
    "# -------------------------\n",
    "# Pretrained model loaders\n",
    "# -------------------------\n",
    "def load_pretrained_alexnet(num_classes_expected: int, device: torch.device):\n",
    "    model = models.alexnet(pretrained=True)\n",
    "    if num_classes_expected != 1000:\n",
    "        # Replace final layer to match labels (user dataset labels)\n",
    "        in_feats = model.classifier[-1].in_features\n",
    "        model.classifier[-1] = nn.Linear(in_feats, num_classes_expected)\n",
    "        # note: the new head is random init (we're not training it here)\n",
    "        print(f\"[warning] AlexNet: dataset has {num_classes_expected} classes != 1000; final layer replaced (random init).\")\n",
    "    return model.to(device)\n",
    "\n",
    "def load_pretrained_vgg16(num_classes_expected: int, device: torch.device):\n",
    "    model = models.vgg16(pretrained=True)\n",
    "    if num_classes_expected != 1000:\n",
    "        in_feats = model.classifier[-1].in_features\n",
    "        model.classifier[-1] = nn.Linear(in_feats, num_classes_expected)\n",
    "        print(f\"[warning] VGG16: dataset has {num_classes_expected} classes != 1000; final layer replaced (random init).\")\n",
    "    return model.to(device)\n",
    "\n",
    "def load_pretrained_cornet(num_classes_expected: int, device: torch.device):\n",
    "    # Load CORnet-S (ImageNet-pretrained)\n",
    "    model = cornet_s(pretrained=True)\n",
    "\n",
    "    # CORnet-S classifier is `decoder`\n",
    "    if num_classes_expected != 1000:\n",
    "        in_feats = model.decoder.in_features\n",
    "        model.decoder = nn.Linear(in_feats, num_classes_expected)\n",
    "        print(\n",
    "            f\"[warning] CORnet-S: dataset has {num_classes_expected} classes != 1000; \"\n",
    "            \"final layer replaced (random init).\"\n",
    "        )\n",
    "    return model.to(device)\n",
    "# -------------------------\n",
    "# Main runner: ALL images are test set\n",
    "# -------------------------\n",
    "def eval_pretrained_on_all_test(\n",
    "    data_dir: str,\n",
    "    batch_size: int = 128,\n",
    "    num_workers: int = 4,\n",
    "    device: str | None = None,\n",
    "    models_to_run: List[str] = (\"alexnet\", \"vgg16\", \"cornet_s\"),\n",
    "    epsilons: List[float] = (0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.2, 0.3, 0.5),\n",
    "):\n",
    "    \"\"\"\n",
    "    Evaluate pretrained AlexNet/VGG16 on ALL images in `data_dir` (root/class_x/*.jpg).\n",
    "    All images are treated as test samples (no splitting, no training).\n",
    "    Returns a dict with clean and adversarial accuracies per model.\n",
    "    \"\"\"\n",
    "    device = torch.device(device if device else (\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "    print(f\"[eval_pretrained_on_all_test] using device: {device}\")\n",
    "\n",
    "    samples, class_map = build_all_test_samples(data_dir)\n",
    "    n_classes = len(class_map)\n",
    "    print(f\"Found {n_classes} classes and {len(samples)} total images (all used as test samples).\")\n",
    "\n",
    "    # Deterministic transform (224 x 224), same for all images\n",
    "    input_size = 224\n",
    "    transform = T.Compose([\n",
    "        T.Resize(256),\n",
    "        T.CenterCrop(224),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
    "    ])\n",
    "\n",
    "    test_ds = AllImagesAsTestDataset(samples, transform=transform)\n",
    "    test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "    results = {}\n",
    "    for model_name in models_to_run:\n",
    "        model_name = model_name.lower()\n",
    "        if model_name == \"alexnet\":\n",
    "            model = load_pretrained_alexnet(n_classes, device)\n",
    "        elif model_name == \"vgg16\":\n",
    "            model = load_pretrained_vgg16(n_classes, device)\n",
    "        elif model_name in (\"cornet\", \"cornet_s\"):\n",
    "            model = load_pretrained_cornet(n_classes, device)\n",
    "        else:\n",
    "            print(f\"[eval_pretrained_on_all_test] unknown model '{model_name}' - skipping\")\n",
    "            continue\n",
    "\n",
    "        print(f\"\\n--- Evaluating {model_name} on full dataset ---\")\n",
    "        clean_acc = evaluate_clean(model, test_loader, device)\n",
    "        print(f\"{model_name} clean accuracy: {clean_acc:.4f}\")\n",
    "\n",
    "        adv_accs = evaluate_fgsm(model, test_loader, device, list(epsilons), loss_fn=nn.CrossEntropyLoss())\n",
    "        for eps, acc in adv_accs.items():\n",
    "            print(f\"{model_name} FGSM eps={eps:.4g} adv accuracy: {acc:.4f}; acc percent: {acc*100:.2f}%\")\n",
    "\n",
    "        results[model_name] = {\"clean_acc\": clean_acc, \"adv_accs\": adv_accs}\n",
    "\n",
    "    print(\"[eval_pretrained_on_all_test] done.\")\n",
    "    return results\n",
    "\n",
    "# -------------------------\n",
    "# Example usage (edit path):\n",
    "# -------------------------\n",
    "# /imaging/mrahm326/val/\n",
    "results = eval_pretrained_on_all_test(\n",
    "    \"val/val/\", batch_size=16, device=\"cuda:0\",\n",
    "    models_to_run=(\"alexnet\", \"vgg16\", \"cornet\"))\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f1ed52",
   "metadata": {},
   "source": [
    "BEFORE CHANGING EPSILONS TO MY RANGE OF EPSILONS\n",
    "--- Evaluating alexnet on full dataset ---\n",
    "alexnet clean accuracy: 0.5631\n",
    "alexnet FGSM eps=0.1 adv accuracy: 0.0054; acc percent: 0.54%\n",
    "alexnet FGSM eps=0.01 adv accuracy: 0.1637; acc percent: 16.37%\n",
    "alexnet FGSM eps=0.005 adv accuracy: 0.3026; acc percent: 30.26%\n",
    "alexnet FGSM eps=0.001 adv accuracy: 0.4986; acc percent: 49.86%\n",
    "/home/nsakr2/.conda/envs/condavenv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
    "  warnings.warn(msg)\n",
    "\n",
    "--- Evaluating vgg16 on full dataset ---\n",
    "vgg16 clean accuracy: 0.7043\n",
    "vgg16 FGSM eps=0.1 adv accuracy: 0.0298; acc percent: 2.98%\n",
    "vgg16 FGSM eps=0.01 adv accuracy: 0.1318; acc percent: 13.18%\n",
    "vgg16 FGSM eps=0.005 adv accuracy: 0.2796; acc percent: 27.96%\n",
    "vgg16 FGSM eps=0.001 adv accuracy: 0.5927; acc percent: 59.27%\n",
    "\n",
    "--- Evaluating cornet on full dataset ---\n",
    "cornet clean accuracy: 0.7214\n",
    "cornet FGSM eps=0.1 adv accuracy: 0.0298; acc percent: 2.98%\n",
    "cornet FGSM eps=0.01 adv accuracy: 0.1960; acc percent: 19.60%\n",
    "cornet FGSM eps=0.005 adv accuracy: 0.3569; acc percent: 35.69%\n",
    "cornet FGSM eps=0.001 adv accuracy: 0.6289; acc percent: 62.89%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "condavenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
