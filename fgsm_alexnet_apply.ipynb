{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9251470",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2238228/1827167652.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import os, glob, json, time, re\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d370bcc4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transforms' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2238228/632404789.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpaths\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n\u001b[0m\u001b[1;32m     10\u001b[0m                                  std=[0.229, 0.224, 0.225])\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'transforms' is not defined"
     ]
    }
   ],
   "source": [
    "# Helper functions (adapted from fgsm_helperfxnsOG)\n",
    "def get_all_image_paths(root_dir):\n",
    "    image_extensions = [\"*.JPEG\", \"*.jpeg\", \"*.JPG\", \"*.jpg\", \"*.png\"]\n",
    "    paths = []\n",
    "    for ext in image_extensions:\n",
    "        paths.extend(glob.glob(os.path.join(root_dir, \"**\", ext), recursive=True))\n",
    "    return paths\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "def get_input_batch(device, filename):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])\n",
    "    image = Image.open(filename).convert('RGB')\n",
    "    tensor = transform(image).unsqueeze(0).to(device)\n",
    "    return tensor\n",
    "\n",
    "with open(\"imagenet_class_index.json\") as f:\n",
    "    imagenet_classes = json.load(f)\n",
    "imagenet_classes = {int(k): v[1] for k,v in imagenet_classes.items()}\n",
    "\n",
    "def output_prediction(model, input_batch):\n",
    "    with torch.no_grad():\n",
    "        output = model(input_batch)\n",
    "    _, pred = torch.max(output, 1)\n",
    "    return pred.item()\n",
    "\n",
    "def extract_true_label(filepath):\n",
    "    # assumes val/val/class_xxx/... structure OR adversarial filename pattern\n",
    "    parent = os.path.basename(os.path.dirname(filepath))\n",
    "    if \"_\" in parent:\n",
    "        return None, parent.split(\"_\",1)[1]\n",
    "    stem = os.path.splitext(os.path.basename(filepath))[0]\n",
    "    return None, stem.split(\"_\")[-1]\n",
    "\n",
    "def compare_labels(pred_index, true_index):\n",
    "    return pred_index == true_index\n",
    "\n",
    "def fgsm_attack(image, epsilon, data_grad):\n",
    "    sign_data_grad = data_grad.sign()\n",
    "    perturbed_image = image + epsilon*sign_data_grad\n",
    "    return torch.clamp(perturbed_image, 0, 1)\n",
    "\n",
    "\n",
    "def save_adv_image(tensor, eps, true_label, true_index, pred_before, pred_after, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    filename = f\"adv_{true_label}_eps{eps}_pred{pred_after}.png\"\n",
    "    save_path = os.path.join(output_dir, filename)\n",
    "    inv_normalize = transforms.Normalize(\n",
    "        mean=[-m/s for m,s in zip([0.485,0.456,0.406],[0.229,0.224,0.225])],\n",
    "        std=[1/s for s in [0.229,0.224,0.225]]\n",
    "    )\n",
    "    img = inv_normalize(tensor.squeeze().cpu()).clamp(0,1)\n",
    "    img = transforms.ToPILImage()(img)\n",
    "    img.save(save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27777c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Section 2: FGSM Experiment Pipeline ---\n",
    "\n",
    "def run_fgsm_experiment(root_dir, epsilons, output_root=\"adv_ALEX_outputs\"):\n",
    "    all_images = get_all_image_paths(root_dir)\n",
    "    \n",
    "    correct_before = 0\n",
    "    total_images = 0\n",
    "    correct_after_per_eps = {eps:0 for eps in epsilons}\n",
    "    total_per_eps = {eps:0 for eps in epsilons}\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = models.alexnet(pretrained=True).to(device)\n",
    "    model.eval()\n",
    "\n",
    "    for filename in tqdm.tqdm(all_images):\n",
    "        try:\n",
    "            total_images += 1\n",
    "            input_batch = get_input_batch(device, filename)\n",
    "\n",
    "            _, true_label = extract_true_label(filename)\n",
    "\n",
    "            pred_before = output_prediction(model, input_batch)\n",
    "\n",
    "            # compare before attack\n",
    "            if imagenet_classes.get(pred_before,\"?\") == true_label:\n",
    "                correct_before += 1\n",
    "\n",
    "                for eps in epsilons:\n",
    "                    input_batch = get_input_batch(device, filename)\n",
    "                    input_batch.requires_grad = True\n",
    "                    output = model(input_batch)\n",
    "                    target = torch.tensor([pred_before]).to(device)\n",
    "                    loss = F.nll_loss(F.log_softmax(output, dim=1), target)\n",
    "                    model.zero_grad()\n",
    "                    loss.backward()\n",
    "\n",
    "                    data_grad = input_batch.grad.data\n",
    "                    perturbed_image = fgsm_attack(input_batch, eps, data_grad)\n",
    "\n",
    "                    output = model(perturbed_image)\n",
    "                    _, pred_after = torch.max(output, 1)\n",
    "\n",
    "                    save_adv_image(perturbed_image, eps, true_label, None, pred_before, pred_after.item(), os.path.join(output_root,f\"eps{eps}\"))\n",
    "\n",
    "                    total_per_eps[eps]+=1\n",
    "                    if imagenet_classes.get(pred_after.item(),\"?\") == true_label:\n",
    "                        correct_after_per_eps[eps]+=1\n",
    "        except Exception as e:\n",
    "            print(f\"Error {filename}: {e}\")\n",
    "\n",
    "    print(f\"Correct before FGSM: {correct_before}/{total_images} = {correct_before/total_images:.2%}\")\n",
    "    for eps in epsilons:\n",
    "        if total_per_eps[eps]>0:\n",
    "            acc = correct_after_per_eps[eps]/total_per_eps[eps]\n",
    "            print(f\"Epsilon {eps}: {correct_after_per_eps[eps]}/{total_per_eps[eps]} = {acc:.2%}\")\n",
    "        else:\n",
    "            print(f\"Epsilon {eps}: No samples.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b72ce971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Section 3: AlexNet Testing Pipeline ---\n",
    "\n",
    "def test_alexnet_on_folder(data_path, imsize=224):\n",
    "    model = models.alexnet(pretrained=True)\n",
    "    model.eval()\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((imsize,imsize)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ])\n",
    "\n",
    "    fnames=[]\n",
    "    for ext in [\"*.JPEG\",\"*.jpeg\",\"*.JPG\",\"*.jpg\",\"*.png\"]:\n",
    "        fnames.extend(glob.glob(os.path.join(data_path,\"**\",ext), recursive=True))\n",
    "    if len(fnames)==0:\n",
    "        raise FileNotFoundError(f\"No files in {data_path}\")\n",
    "\n",
    "    count=0\n",
    "    for f in tqdm.tqdm(fnames):\n",
    "        try:\n",
    "            im = Image.open(f).convert('RGB')\n",
    "        except:\n",
    "            continue\n",
    "        im = transform(im).unsqueeze(0)\n",
    "        outputs = model(im)\n",
    "        _, pred_idx = torch.max(outputs,1)\n",
    "        pred_label = imagenet_classes.get(pred_idx.item(),\"Unknown\")\n",
    "\n",
    "        true_label = extract_true_label(f)[1]\n",
    "\n",
    "        if true_label == pred_label:\n",
    "            count+=1\n",
    "\n",
    "    accuracy = (count/len(fnames))*100\n",
    "    print(f\"Accuracy: {count}/{len(fnames)} = {accuracy:.2f}%\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86aa0a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Section 4: Example Usage ---\n",
    "run_fgsm_experiment(\"val/val\", [0.01,0.05,0.1])\n",
    "test_alexnet_on_folder(\"adv_ALEX_outputs/eps0.05\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
