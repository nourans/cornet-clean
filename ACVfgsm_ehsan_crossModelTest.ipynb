{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c825064",
   "metadata": {},
   "source": [
    "Cross Model Testing: This file is my implementation of ehsan's code for  testing model A on the images generated by model B (FGSM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39721d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac80929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FGSM-AlexNet - Running on full dataset: 3923 total images\n",
    "# Put this into a Jupyter notebook cell\n",
    "from __future__ import annotations\n",
    "import os\n",
    "from cornet import cornet_s\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "\n",
    "# -------------------------\n",
    "# Dataset: ALL images = test set\n",
    "# -------------------------\n",
    "class AllImagesAsTestDataset(Dataset):\n",
    "    \"\"\"Wraps a list of (image_path, label) - used as the entire test set (no split).\"\"\"\n",
    "    def __init__(self, samples: List[Tuple[str, int]], transform=None):\n",
    "        self.samples = samples\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        p, label = self.samples[idx]\n",
    "        img = Image.open(p).convert(\"RGB\")\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n",
    "\n",
    "def build_all_test_samples(root: str, sort_filenames: bool = True) -> Tuple[List[Tuple[str,int]], Dict[int, str]]:\n",
    "    \"\"\"\n",
    "    Walks `root` and builds a list of (image_path, label) for *all* files in each class folder.\n",
    "    Label assigned by sorted folder order. Returns samples and class_map.\n",
    "    \"\"\"\n",
    "    root_p = Path(root)\n",
    "    assert root_p.exists(), f\"Data root not found: {root}\"\n",
    "    class_dirs = sorted([d for d in root_p.iterdir() if d.is_dir()])\n",
    "    samples = []\n",
    "    class_map = {}\n",
    "    for label, cls in enumerate(class_dirs):\n",
    "        imgs = [p for p in cls.iterdir() if p.is_file()]\n",
    "        if sort_filenames:\n",
    "            imgs = sorted(imgs)\n",
    "        for p in imgs:\n",
    "            samples.append((str(p), label))\n",
    "        class_map[label] = cls.name\n",
    "    return samples, class_map\n",
    "\n",
    "# -------------------------\n",
    "# FGSM helper (normalized-space)\n",
    "# -------------------------\n",
    "def fgsm_perturb_from_grad(x: torch.Tensor, grad: torch.Tensor, epsilon: float) -> torch.Tensor:\n",
    "    \"\"\"Return perturbed inputs in normalized input space using gradient sign.\"\"\"\n",
    "    return torch.clamp(x + epsilon * grad.sign(), -10.0, 10.0).detach()\n",
    "\n",
    "# -------------------------\n",
    "# Evaluation (clean + FGSM)\n",
    "# -------------------------\n",
    "def evaluate_clean(model: nn.Module, loader: DataLoader, device: torch.device) -> float:\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            out = model(x)\n",
    "            preds = out.argmax(dim=1)\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += y.size(0)\n",
    "    return (correct / total) if total > 0 else 0.0\n",
    "\n",
    "def evaluate_fgsm_cross(\n",
    "        generating_model: nn.Module, \n",
    "        predicting_model: nn.Module,\n",
    "        loader: DataLoader, \n",
    "        device: torch.device,\n",
    "        epsilons: List[float], \n",
    "        loss_fn=None\n",
    ") -> Dict[float, float]:\n",
    "    if loss_fn is None:\n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "    generating_model.eval()\n",
    "    predicting_model.eval()\n",
    "    results = {eps: {'correct': 0, 'total': 0} for eps in epsilons}\n",
    "\n",
    "    for x, y in loader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        # generating perturbed image using model A\n",
    "        x.requires_grad = True\n",
    "        out = generating_model(x)\n",
    "        loss = loss_fn(out, y)\n",
    "\n",
    "        generating_model.zero_grad()\n",
    "        loss.backward()\n",
    "        grad = x.grad.data\n",
    "        # getting the perdiction using model B\n",
    "        for eps in epsilons:\n",
    "            x_adv = fgsm_perturb_from_grad(x, grad, eps)\n",
    "            with torch.no_grad():\n",
    "                out_adv = predicting_model(x_adv)\n",
    "                preds = out_adv.argmax(dim=1)\n",
    "                results[eps]['correct'] += (preds == y).sum().item()\n",
    "                results[eps]['total'] += y.size(0)\n",
    "        x.grad = None\n",
    "\n",
    "    return {eps: (results[eps]['correct'] / results[eps]['total'] if results[eps]['total'] > 0 else 0.0)\n",
    "            for eps in epsilons}\n",
    "\n",
    "# -------------------------\n",
    "# Pretrained model loaders\n",
    "# -------------------------\n",
    "def load_pretrained_alexnet(num_classes_expected: int, device: torch.device):\n",
    "    model = models.alexnet(pretrained=True)\n",
    "    if num_classes_expected != 1000:\n",
    "        # replace final layer to match labels\n",
    "        in_feats = model.classifier[-1].in_features\n",
    "        model.classifier[-1] = nn.Linear(in_feats, num_classes_expected)\n",
    "        print(f\"[warning] AlexNet: dataset has {num_classes_expected} classes != 1000; final layer replaced (random init).\")\n",
    "    return model.to(device)\n",
    "\n",
    "def load_pretrained_vgg16(num_classes_expected: int, device: torch.device):\n",
    "    model = models.vgg16(pretrained=True)\n",
    "    if num_classes_expected != 1000:\n",
    "        in_feats = model.classifier[-1].in_features\n",
    "        model.classifier[-1] = nn.Linear(in_feats, num_classes_expected)\n",
    "        print(f\"[warning] VGG16: dataset has {num_classes_expected} classes != 1000; final layer replaced (random init).\")\n",
    "    return model.to(device)\n",
    "\n",
    "def load_pretrained_cornet(num_classes_expected: int, device: torch.device):\n",
    "    # load CORnet-S (pretrained on imagenet)\n",
    "    model = cornet_s(pretrained=True)\n",
    "\n",
    "    # CORnet-S classifier is decoder\n",
    "    if num_classes_expected != 1000:\n",
    "        in_feats = model.decoder.in_features\n",
    "        model.decoder = nn.Linear(in_feats, num_classes_expected)\n",
    "        print(\n",
    "            f\"[warning] CORnet-S: dataset has {num_classes_expected} classes != 1000; \"\n",
    "            \"final layer replaced (random init).\"\n",
    "        )\n",
    "    return model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27155adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_pretrained_on_all_test(\n",
    "    data_dir: str,\n",
    "    gen_model_name: str,\n",
    "    pred_model_name: str,\n",
    "    batch_size: int = 128,\n",
    "    num_workers: int = 4,\n",
    "    device: str | None = None,\n",
    "    epsilons: List[float] = (0.005, 0.01, 0.02, 0.03, 0.05, 0.1, 0.2, 0.3, 0.5),\n",
    "):\n",
    "    \"\"\"\n",
    "    Evaluate pretrained AlexNet/VGG16 on ALL images in `data_dir` (root/class_x/*.jpg).\n",
    "    All images are treated as test samples (no splitting, no training).\n",
    "    Returns a dict with clean and adversarial accuracies per model.\n",
    "    \"\"\"\n",
    "    device = torch.device(device if device else (\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "    print(f\"[eval_pretrained_on_all_test] using device: {device}\")\n",
    "\n",
    "    samples, class_map = build_all_test_samples(data_dir)\n",
    "    n_classes = len(class_map)\n",
    "    print(f\"Found {n_classes} classes and {len(samples)} total images (all used as test samples).\")\n",
    "\n",
    "    # Deterministic transform (224 x 224), same for all images\n",
    "    input_size = 224\n",
    "    transform = T.Compose([\n",
    "        T.Resize(256),\n",
    "        T.CenterCrop(224),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
    "    ])\n",
    "\n",
    "    test_ds = AllImagesAsTestDataset(samples, transform=transform)\n",
    "    test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    # loading generating models\n",
    "    if gen_model_name == \"alexnet\":\n",
    "        gen_model = load_pretrained_alexnet(n_classes, device)\n",
    "    elif gen_model_name in (\"cornet\", \"cornet_s\"):\n",
    "        gen_model = load_pretrained_cornet(n_classes, device)\n",
    "    elif gen_model_name == \"vgg16\":\n",
    "        gen_model = load_pretrained_vgg16(n_classes, device)\n",
    "    else:\n",
    "        print(f\"[eval_pretrained_on_all_test] unknown model '{gen_model_name}' - skipping\")\n",
    "\n",
    "    # loading predictor models\n",
    "    if pred_model_name == \"alexnet\":\n",
    "        pred_model = load_pretrained_alexnet(n_classes, device)\n",
    "    elif pred_model_name in (\"cornet\", \"cornet_s\"):\n",
    "        pred_model = load_pretrained_cornet(n_classes, device)\n",
    "    elif pred_model_name == \"vgg16\":\n",
    "        pred_model = load_pretrained_vgg16(n_classes, device)\n",
    "    else:\n",
    "        print(f\"[eval_pretrained_on_all_test] unknown model '{pred_model_name}' - skipping\")\n",
    "\n",
    "    gen_model.eval()\n",
    "    pred_model.eval()\n",
    "    \n",
    "    clean_acc = evaluate_clean(gen_model, test_loader, device)\n",
    "    print(f\"{gen_model_name} clean accuracy: {clean_acc:.4f} = {clean_acc*100:.2f}%\")\n",
    "\n",
    "    clean_acc = evaluate_clean(pred_model, test_loader, device)\n",
    "    print(f\"{pred_model_name} clean accuracy: {clean_acc:.4f} = {clean_acc*100:.2f}%\")\n",
    "\n",
    "    cross_results = {}\n",
    "\n",
    "    adv_acc = evaluate_fgsm_cross(\n",
    "        generating_model=gen_model, \n",
    "        predicting_model=pred_model,\n",
    "        loader=test_loader, \n",
    "        device=device,\n",
    "        epsilons=list(epsilons), \n",
    "        loss_fn=nn.CrossEntropyLoss()\n",
    "    )\n",
    "    for eps, acc in adv_acc.items():\n",
    "        print(f\"{gen_model_name} generates & {pred_model_name} predicts | eps={eps:.4g} | acc={acc*100:.2f}%\")\n",
    "    \n",
    "    cross_results[pred_model_name] = adv_acc\n",
    "\n",
    "    results[gen_model_name] = {\n",
    "        \"clean_acc\": clean_acc,\n",
    "        \"cross\": cross_results,\n",
    "    }\n",
    "\n",
    "    print(\"[eval_pretrained_on_all_test] done.\")\n",
    "    return results\n",
    "\n",
    "# -------------------------\n",
    "# Example usage (edit path):\n",
    "# -------------------------\n",
    "# /imaging/mrahm326/val/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6be3943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[eval_pretrained_on_all_test] using device: cuda:0\n",
      "Found 1000 classes and 3923 total images (all used as test samples).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nsakr2/.conda/envs/condavenv/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/nsakr2/.conda/envs/condavenv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alexnet clean accuracy: 0.5631 = 56.31%\n",
      "alexnet generates & cornet predicts | eps=0.005 | acc=71.50%\n",
      "[eval_pretrained_on_all_test] done.\n",
      "{'alexnet': {'clean_acc': 0.563089472342595, 'cross': {'cornet': {0.005: 0.7150140198827428}}}}\n"
     ]
    }
   ],
   "source": [
    "# TEST: Alex generates --- COR predicts\n",
    "results = eval_pretrained_on_all_test(\n",
    "    \"val/val/\", gen_model_name=\"alexnet\",\n",
    "    pred_model_name=\"cornet\",\n",
    "    batch_size=16, device=\"cuda:0\", epsilons=[0.005]\n",
    "    )\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe0ec45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[eval_pretrained_on_all_test] using device: cuda:0\n",
      "Found 1000 classes and 3923 total images (all used as test samples).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nsakr2/.conda/envs/condavenv/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/nsakr2/.conda/envs/condavenv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alexnet clean accuracy: 0.5631 = 56.31%\n",
      "cornet clean accuracy: 0.7214 = 72.14%\n",
      "alexnet generates & cornet predicts | eps=0.005 | acc=71.50%\n",
      "alexnet generates & cornet predicts | eps=0.01 | acc=70.76%\n",
      "[eval_pretrained_on_all_test] done.\n",
      "{'alexnet': {'clean_acc': 0.7213866938567423, 'cross': {'cornet': {0.005: 0.7150140198827428, 0.01: 0.7076217180729034}}}}\n"
     ]
    }
   ],
   "source": [
    "# TEST: Alex generates --- COR predicts\n",
    "results = eval_pretrained_on_all_test(\n",
    "    \"val/val/\", gen_model_name=\"alexnet\",\n",
    "    pred_model_name=\"cornet\",\n",
    "    batch_size=16, device=\"cuda:0\", epsilons=[0.005, 0.01]\n",
    "    )\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b14c24ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[eval_pretrained_on_all_test] using device: cuda:0\n",
      "Found 1000 classes and 3923 total images (all used as test samples).\n",
      "alexnet clean accuracy: 0.5631 = 56.31%\n",
      "cornet clean accuracy: 0.7214 = 72.14%\n",
      "alexnet generates & cornet predicts | eps=0.005 | acc=71.50%\n",
      "alexnet generates & cornet predicts | eps=0.01 | acc=70.76%\n",
      "alexnet generates & cornet predicts | eps=0.02 | acc=69.41%\n",
      "alexnet generates & cornet predicts | eps=0.03 | acc=68.03%\n",
      "alexnet generates & cornet predicts | eps=0.05 | acc=64.92%\n",
      "alexnet generates & cornet predicts | eps=0.1 | acc=56.13%\n",
      "alexnet generates & cornet predicts | eps=0.2 | acc=41.19%\n",
      "alexnet generates & cornet predicts | eps=0.3 | acc=27.43%\n",
      "alexnet generates & cornet predicts | eps=0.5 | acc=13.00%\n",
      "[eval_pretrained_on_all_test] done.\n",
      "{'alexnet': {'clean_acc': 0.7213866938567423, 'cross': {'cornet': {0.005: 0.7150140198827428, 0.01: 0.7076217180729034, 0.02: 0.6941116492480245, 0.03: 0.6803466734641855, 0.05: 0.6492480244710681, 0.1: 0.5613051236298751, 0.2: 0.41192964567932705, 0.3: 0.27427988784093804, 0.5: 0.1300025490695896}}}}\n"
     ]
    }
   ],
   "source": [
    "# Alex generates --- COR predicts\n",
    "results = eval_pretrained_on_all_test(\n",
    "    \"val/val/\", gen_model_name=\"alexnet\",\n",
    "    pred_model_name=\"cornet\",\n",
    "    batch_size=16, device=\"cuda:0\"\n",
    "    )\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ea6f65e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALEX generates --- VGG16 predicts\n",
      "\n",
      "\n",
      "[eval_pretrained_on_all_test] using device: cuda:0\n",
      "Found 1000 classes and 3923 total images (all used as test samples).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nsakr2/.conda/envs/condavenv/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/nsakr2/.conda/envs/condavenv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/home/nsakr2/.conda/envs/condavenv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alexnet clean accuracy: 0.5631 = 56.31%\n",
      "vgg16 clean accuracy: 0.7043 = 70.43%\n",
      "alexnet generates & vgg16 predicts | eps=0.005 | acc=69.77%\n",
      "alexnet generates & vgg16 predicts | eps=0.01 | acc=69.26%\n",
      "alexnet generates & vgg16 predicts | eps=0.02 | acc=67.52%\n",
      "alexnet generates & vgg16 predicts | eps=0.03 | acc=65.69%\n",
      "alexnet generates & vgg16 predicts | eps=0.05 | acc=61.99%\n",
      "alexnet generates & vgg16 predicts | eps=0.1 | acc=52.10%\n",
      "alexnet generates & vgg16 predicts | eps=0.2 | acc=31.63%\n",
      "alexnet generates & vgg16 predicts | eps=0.3 | acc=17.77%\n",
      "alexnet generates & vgg16 predicts | eps=0.5 | acc=5.68%\n",
      "[eval_pretrained_on_all_test] done.\n",
      "{'alexnet': {'clean_acc': 0.7043079276064237, 'cross': {'vgg16': {0.005: 0.6976803466734642, 0.01: 0.6925822074942646, 0.02: 0.675248534284986, 0.03: 0.6568952332398674, 0.05: 0.6199337241906704, 0.1: 0.5210298241141983, 0.2: 0.3163395360693347, 0.3: 0.17767015039510578, 0.5: 0.056844251848075456}}}}\n"
     ]
    }
   ],
   "source": [
    "# Alex generates --- VGG16 predicts\n",
    "print(f\"ALEX generates --- VGG16 predicts\\n\\n\")\n",
    "results = eval_pretrained_on_all_test(\n",
    "    \"val/val/\", gen_model_name=\"alexnet\",\n",
    "    pred_model_name=\"vgg16\",\n",
    "    batch_size=16, device=\"cuda:0\"\n",
    "    )\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53995264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COR generates --- ALEX predicts\n",
      "\n",
      "\n",
      "[eval_pretrained_on_all_test] using device: cuda:0\n",
      "Found 1000 classes and 3923 total images (all used as test samples).\n",
      "cornet clean accuracy: 0.7214 = 72.14%\n",
      "alexnet clean accuracy: 0.5631 = 56.31%\n",
      "cornet generates & alexnet predicts | eps=0.005 | acc=55.80%\n",
      "cornet generates & alexnet predicts | eps=0.01 | acc=55.47%\n",
      "cornet generates & alexnet predicts | eps=0.02 | acc=54.42%\n",
      "cornet generates & alexnet predicts | eps=0.03 | acc=53.50%\n",
      "cornet generates & alexnet predicts | eps=0.05 | acc=49.99%\n",
      "cornet generates & alexnet predicts | eps=0.1 | acc=42.37%\n",
      "cornet generates & alexnet predicts | eps=0.2 | acc=27.53%\n",
      "cornet generates & alexnet predicts | eps=0.3 | acc=15.01%\n",
      "cornet generates & alexnet predicts | eps=0.5 | acc=4.03%\n",
      "[eval_pretrained_on_all_test] done.\n",
      "{'cornet': {'clean_acc': 0.563089472342595, 'cross': {'alexnet': {0.005: 0.5579913331633953, 0.01: 0.5546775426969156, 0.02: 0.5442263573795565, 0.03: 0.5350497068569972, 0.05: 0.49987254652052, 0.1: 0.4236553657914861, 0.2: 0.27529951567677796, 0.3: 0.150140198827428, 0.5: 0.04027529951567678}}}}\n"
     ]
    }
   ],
   "source": [
    "# COR generates --- ALEX predicts\n",
    "print(f\"COR generates --- ALEX predicts\\n\\n\")\n",
    "results = eval_pretrained_on_all_test(\n",
    "    \"val/val/\", gen_model_name=\"cornet\",\n",
    "    pred_model_name=\"alexnet\",\n",
    "    batch_size=16, device=\"cuda:0\"\n",
    "    )\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb45cbcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COR generates --- VGG16 predicts\n",
      "\n",
      "\n",
      "[eval_pretrained_on_all_test] using device: cuda:0\n",
      "Found 1000 classes and 3923 total images (all used as test samples).\n",
      "cornet clean accuracy: 0.7214 = 72.14%\n",
      "vgg16 clean accuracy: 0.7043 = 70.43%\n",
      "cornet generates & vgg16 predicts | eps=0.005 | acc=68.03%\n",
      "cornet generates & vgg16 predicts | eps=0.01 | acc=65.18%\n",
      "cornet generates & vgg16 predicts | eps=0.02 | acc=60.31%\n",
      "cornet generates & vgg16 predicts | eps=0.03 | acc=55.95%\n",
      "cornet generates & vgg16 predicts | eps=0.05 | acc=48.38%\n",
      "cornet generates & vgg16 predicts | eps=0.1 | acc=37.93%\n",
      "cornet generates & vgg16 predicts | eps=0.2 | acc=24.37%\n",
      "cornet generates & vgg16 predicts | eps=0.3 | acc=14.89%\n",
      "cornet generates & vgg16 predicts | eps=0.5 | acc=5.17%\n",
      "[eval_pretrained_on_all_test] done.\n",
      "{'cornet': {'clean_acc': 0.7043079276064237, 'cross': {'vgg16': {0.005: 0.6803466734641855, 0.01: 0.6517970940606679, 0.02: 0.6031098648993117, 0.03: 0.5595207749171552, 0.05: 0.4838134081060413, 0.1: 0.37930155493244966, 0.2: 0.24369105276574052, 0.3: 0.1488656640326281, 0.5: 0.05174611266887586}}}}\n"
     ]
    }
   ],
   "source": [
    "# COR generates --- VGG16 predicts\n",
    "print(f\"COR generates --- VGG16 predicts\\n\\n\")\n",
    "results = eval_pretrained_on_all_test(\n",
    "    \"val/val/\", gen_model_name=\"cornet\",\n",
    "    pred_model_name=\"vgg16\",\n",
    "    batch_size=16, device=\"cuda:0\"\n",
    "    )\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "367d9f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG16 generates --- ALEX predicts\n",
      "\n",
      "\n",
      "[eval_pretrained_on_all_test] using device: cuda:0\n",
      "Found 1000 classes and 3923 total images (all used as test samples).\n",
      "vgg16 clean accuracy: 0.7043 = 70.43%\n",
      "alexnet clean accuracy: 0.5631 = 56.31%\n",
      "vgg16 generates & alexnet predicts | eps=0.005 | acc=55.85%\n",
      "vgg16 generates & alexnet predicts | eps=0.01 | acc=55.60%\n",
      "vgg16 generates & alexnet predicts | eps=0.02 | acc=54.80%\n",
      "vgg16 generates & alexnet predicts | eps=0.03 | acc=53.89%\n",
      "vgg16 generates & alexnet predicts | eps=0.05 | acc=51.62%\n",
      "vgg16 generates & alexnet predicts | eps=0.1 | acc=44.94%\n",
      "vgg16 generates & alexnet predicts | eps=0.2 | acc=30.10%\n",
      "vgg16 generates & alexnet predicts | eps=0.3 | acc=17.61%\n",
      "vgg16 generates & alexnet predicts | eps=0.5 | acc=4.79%\n",
      "[eval_pretrained_on_all_test] done.\n",
      "{'vgg16': {'clean_acc': 0.563089472342595, 'cross': {'alexnet': {0.005: 0.5585011470813154, 0.01: 0.5559520774917155, 0.02: 0.5480499617639562, 0.03: 0.5388733112413969, 0.05: 0.5161865918939587, 0.1: 0.449400968646444, 0.2: 0.30104511853173593, 0.3: 0.1761407086413459, 0.5: 0.04792250828447617}}}}\n"
     ]
    }
   ],
   "source": [
    "# VGG16 generates --- ALEX predicts\n",
    "print(f\"VGG16 generates --- ALEX predicts\\n\\n\")\n",
    "results = eval_pretrained_on_all_test(\n",
    "    \"val/val/\", gen_model_name=\"vgg16\",\n",
    "    pred_model_name=\"alexnet\",\n",
    "    batch_size=16, device=\"cuda:0\"\n",
    "    )\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7e7bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG16 generates --- COR predicts\n",
      "\n",
      "\n",
      "[eval_pretrained_on_all_test] using device: cuda:0\n",
      "Found 1000 classes and 3923 total images (all used as test samples).\n",
      "vgg16 clean accuracy: 0.7043 = 70.43%\n",
      "cornet clean accuracy: 0.7214 = 72.14%\n",
      "vgg16 generates & cornet predicts | eps=0.005 | acc=70.02%\n",
      "vgg16 generates & cornet predicts | eps=0.01 | acc=67.93%\n",
      "vgg16 generates & cornet predicts | eps=0.02 | acc=64.11%\n",
      "vgg16 generates & cornet predicts | eps=0.03 | acc=61.02%\n",
      "vgg16 generates & cornet predicts | eps=0.05 | acc=55.72%\n",
      "vgg16 generates & cornet predicts | eps=0.1 | acc=47.77%\n",
      "vgg16 generates & cornet predicts | eps=0.2 | acc=37.80%\n",
      "vgg16 generates & cornet predicts | eps=0.3 | acc=31.23%\n",
      "vgg16 generates & cornet predicts | eps=0.5 | acc=19.27%\n",
      "[eval_pretrained_on_all_test] done.\n",
      "{'vgg16': {'clean_acc': 0.7213866938567423, 'cross': {'cornet': {0.005: 0.700229416263064, 0.01: 0.6793270456283457, 0.02: 0.6410910017843487, 0.03: 0.6102472597501912, 0.05: 0.5572266122865154, 0.1: 0.47769564109100177, 0.2: 0.37802702013764977, 0.3: 0.312261024725975, 0.5: 0.1927096609737446}}}}\n"
     ]
    }
   ],
   "source": [
    "# VGG16 generates --- COR predicts\n",
    "print(f\"VGG16 generates --- COR predicts\\n\\n\")\n",
    "results = eval_pretrained_on_all_test(\n",
    "    \"val/val/\", gen_model_name=\"vgg16\",\n",
    "    pred_model_name=\"cornet\",\n",
    "    batch_size=16, device=\"cuda:0\"\n",
    "    )\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38c73d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALEX generates --- ALEX predicts\n",
      "\n",
      "\n",
      "[eval_pretrained_on_all_test] using device: cuda:0\n",
      "Found 1000 classes and 3923 total images (all used as test samples).\n",
      "alexnet clean accuracy: 0.5631 = 56.31%\n",
      "alexnet clean accuracy: 0.5631 = 56.31%\n",
      "alexnet generates & alexnet predicts | eps=0.005 | acc=30.26%\n",
      "alexnet generates & alexnet predicts | eps=0.01 | acc=16.37%\n",
      "alexnet generates & alexnet predicts | eps=0.02 | acc=6.12%\n",
      "alexnet generates & alexnet predicts | eps=0.03 | acc=3.03%\n",
      "alexnet generates & alexnet predicts | eps=0.05 | acc=1.12%\n",
      "alexnet generates & alexnet predicts | eps=0.1 | acc=0.54%\n",
      "alexnet generates & alexnet predicts | eps=0.2 | acc=0.46%\n",
      "alexnet generates & alexnet predicts | eps=0.3 | acc=0.28%\n",
      "alexnet generates & alexnet predicts | eps=0.5 | acc=0.20%\n",
      "[eval_pretrained_on_all_test] done.\n",
      "{'alexnet': {'clean_acc': 0.563089472342595, 'cross': {'alexnet': {0.005: 0.3025745602854958, 0.01: 0.16365026765230692, 0.02: 0.0611776701503951, 0.03: 0.030333928116237575, 0.05: 0.011215906194239103, 0.1: 0.005353046138159572, 0.2: 0.004588325261279633, 0.3: 0.002803976548559776, 0.5: 0.002039255671679837}}}}\n"
     ]
    }
   ],
   "source": [
    "# ALEX generates --- ALEX predicts\n",
    "print(f\"ALEX generates --- ALEX predicts\\n\\n\")\n",
    "results = eval_pretrained_on_all_test(\n",
    "    \"val/val/\", gen_model_name=\"alexnet\",\n",
    "    pred_model_name=\"alexnet\",\n",
    "    batch_size=16, device=\"cuda:0\"\n",
    "    )\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42f4ada2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COR generates --- COR predicts\n",
      "\n",
      "\n",
      "[eval_pretrained_on_all_test] using device: cuda:0\n",
      "Found 1000 classes and 3923 total images (all used as test samples).\n",
      "cornet clean accuracy: 0.7214 = 72.14%\n",
      "cornet clean accuracy: 0.7214 = 72.14%\n",
      "cornet generates & cornet predicts | eps=0.005 | acc=35.69%\n",
      "cornet generates & cornet predicts | eps=0.01 | acc=19.60%\n",
      "cornet generates & cornet predicts | eps=0.02 | acc=7.95%\n",
      "cornet generates & cornet predicts | eps=0.03 | acc=5.10%\n",
      "cornet generates & cornet predicts | eps=0.05 | acc=3.39%\n",
      "cornet generates & cornet predicts | eps=0.1 | acc=2.98%\n",
      "cornet generates & cornet predicts | eps=0.2 | acc=3.52%\n",
      "cornet generates & cornet predicts | eps=0.3 | acc=3.93%\n",
      "cornet generates & cornet predicts | eps=0.5 | acc=4.36%\n",
      "[eval_pretrained_on_all_test] done.\n",
      "{'cornet': {'clean_acc': 0.7213866938567423, 'cross': {'cornet': {0.005: 0.35686974254397147, 0.01: 0.19602345144022432, 0.02: 0.07953097119551364, 0.03: 0.05098139179199592, 0.05: 0.033902625541677285, 0.1: 0.029824114198317615, 0.2: 0.035177160336477185, 0.3: 0.03925567167983686, 0.5: 0.04358908998215651}}}}\n"
     ]
    }
   ],
   "source": [
    "# COR generates --- COR predicts\n",
    "print(f\"COR generates --- COR predicts\\n\\n\")\n",
    "results = eval_pretrained_on_all_test(\n",
    "    \"val/val/\", gen_model_name=\"cornet\",\n",
    "    pred_model_name=\"cornet\",\n",
    "    batch_size=16, device=\"cuda:0\"\n",
    "    )\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3939acb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG generates --- VGG predicts\n",
      "\n",
      "\n",
      "[eval_pretrained_on_all_test] using device: cuda:0\n",
      "Found 1000 classes and 3923 total images (all used as test samples).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nsakr2/.conda/envs/condavenv/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/nsakr2/.conda/envs/condavenv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vgg16 clean accuracy: 0.7043 = 70.43%\n",
      "vgg16 clean accuracy: 0.7043 = 70.43%\n",
      "vgg16 generates & vgg16 predicts | eps=0.005 | acc=27.96%\n",
      "vgg16 generates & vgg16 predicts | eps=0.01 | acc=13.18%\n",
      "vgg16 generates & vgg16 predicts | eps=0.02 | acc=5.51%\n",
      "vgg16 generates & vgg16 predicts | eps=0.03 | acc=3.67%\n",
      "vgg16 generates & vgg16 predicts | eps=0.05 | acc=2.96%\n",
      "vgg16 generates & vgg16 predicts | eps=0.1 | acc=2.98%\n",
      "vgg16 generates & vgg16 predicts | eps=0.2 | acc=3.62%\n",
      "vgg16 generates & vgg16 predicts | eps=0.3 | acc=3.67%\n",
      "vgg16 generates & vgg16 predicts | eps=0.5 | acc=2.75%\n",
      "[eval_pretrained_on_all_test] done.\n",
      "{'vgg16': {'clean_acc': 0.7043079276064237, 'cross': {'vgg16': {0.005: 0.2796329339790976, 0.01: 0.13178689778230945, 0.02: 0.055059903135355595, 0.03: 0.036706602090237066, 0.05: 0.029569207239357635, 0.1: 0.029824114198317615, 0.2: 0.036196788172317106, 0.3: 0.036706602090237066, 0.5: 0.027529951567677798}}}}\n"
     ]
    }
   ],
   "source": [
    "# VGG generates --- VGG predicts\n",
    "print(f\"VGG generates --- VGG predicts\\n\\n\")\n",
    "results = eval_pretrained_on_all_test(\n",
    "    \"val/val/\", gen_model_name=\"vgg16\",\n",
    "    pred_model_name=\"vgg16\",\n",
    "    batch_size=16, device=\"cuda:0\"\n",
    "    )\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f133661",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "condavenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
